{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v0.1 ...\n",
      "23 category,\n",
      "8 attribute,\n",
      "5 visibility,\n",
      "6975 instance,\n",
      "12 sensor,\n",
      "1200 calibrated_sensor,\n",
      "304715 ego_pose,\n",
      "12 log,\n",
      "100 scene,\n",
      "3977 sample,\n",
      "304715 sample_data,\n",
      "99952 sample_annotation,\n",
      "12 map,\n",
      "Done loading in 5.3 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 1.5 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "# Let's start by initializing the database\n",
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pcl\n",
    "\n",
    "nusc = NuScenes(version='v0.1', dataroot='/data/nuscenes', verbose=True)\n",
    "\n",
    "# Get test token\n",
    "my_scene_token = nusc.field2token('scene', 'name', 'scene-0001')[0]\n",
    "scene_rec = nusc.get('scene',my_scene_token)\n",
    "nusc.get('sample',scene_rec['first_sample_token'])\n",
    "\n",
    "# Get points data\n",
    "points = nusc.get_pointcloud_position('3388933b59444c5db71fade0bbfef470')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pcl\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "\n",
    "points = points.astype(np.float32)\n",
    "cloud = pcl.PointCloud(points.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-554dd993e32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pointcloud.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "# save as mat\n",
    "import scipy.io as scio\n",
    "scio.savemat('pointcloud.mat', {'A':points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_indices : <built-in method count of list object at 0x7f21e2b256c8> count.\n",
      "indices = 5719\n",
      "[[ 0.00503874 -0.10467585]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "indices = 1770\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 349\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 222\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 220\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 3.65071893e-01 -4.98768151e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 210\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 3.65071893e-01 -4.98768151e-01]\n",
      " [-3.04406524e-01 -5.95700741e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 109\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 3.65071893e-01 -4.98768151e-01]\n",
      " [-3.04406524e-01 -5.95700741e-01]\n",
      " [ 3.19517553e-01 -5.84820926e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 106\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 3.65071893e-01 -4.98768151e-01]\n",
      " [-3.04406524e-01 -5.95700741e-01]\n",
      " [ 3.19517553e-01 -5.84820926e-01]\n",
      " [ 2.95301974e-01 -6.61911011e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00]]\n",
      "indices = 103\n",
      "[[ 5.03873592e-03 -1.04675852e-01]\n",
      " [ 2.76446342e-04  3.04824382e-01]\n",
      " [ 1.91787958e-01 -7.78818309e-01]\n",
      " [-3.51267517e-01 -4.65270817e-01]\n",
      " [ 3.65071893e-01 -4.98768151e-01]\n",
      " [-3.04406524e-01 -5.95700741e-01]\n",
      " [ 3.19517553e-01 -5.84820926e-01]\n",
      " [ 2.95301974e-01 -6.61911011e-01]\n",
      " [ 4.65759724e-01 -6.09172694e-03]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Euclidean Cluster Extraction\n",
    "# http://pointclouds.org/documentation/tutorials/cluster_extraction.php#cluster-extraction\n",
    "import numpy as np\n",
    "import pcl\n",
    "import scipy.io as scio\n",
    "\n",
    "# int main (int argc, char** argv)\n",
    "# {\n",
    "#   // Read in the cloud data\n",
    "#   pcl::PCDReader reader;\n",
    "#   pcl::PointCloud<pcl::PointXYZ>::Ptr cloud (new pcl::PointCloud<pcl::PointXYZ>), cloud_f (new pcl::PointCloud<pcl::PointXYZ>);\n",
    "#   reader.read (\"table_scene_lms400.pcd\", *cloud);\n",
    "#   std::cout << \"PointCloud before filtering has: \" << cloud->points.size () << \" data points.\" << std::endl; //*\n",
    "\n",
    "#   // Create the filtering object: downsample the dataset using a leaf size of 1cm\n",
    "#   pcl::VoxelGrid<pcl::PointXYZ> vg;\n",
    "#   pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_filtered (new pcl::PointCloud<pcl::PointXYZ>);\n",
    "#   vg.setInputCloud (cloud);\n",
    "#   vg.setLeafSize (0.01f, 0.01f, 0.01f);\n",
    "#   vg.filter (*cloud_filtered);\n",
    "#   std::cout << \"PointCloud after filtering has: \" << cloud_filtered->points.size ()  << \" data points.\" << std::endl; //*\n",
    "vg = cloud.make_voxel_grid_filter()\n",
    "vg.set_leaf_size (0.01, 0.01, 0.01)\n",
    "cloud_filtered = vg.filter ()\n",
    "\n",
    "#   // Create the segmentation object for the planar model and set all the parameters\n",
    "#   pcl::SACSegmentation<pcl::PointXYZ> seg;\n",
    "#   pcl::PointIndices::Ptr inliers (new pcl::PointIndices);\n",
    "#   pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);\n",
    "#   pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_plane (new pcl::PointCloud<pcl::PointXYZ> ());\n",
    "#   pcl::PCDWriter writer;\n",
    "#   seg.setOptimizeCoefficients (true);\n",
    "#   seg.setModelType (pcl::SACMODEL_PLANE);\n",
    "#   seg.setMethodType (pcl::SAC_RANSAC);\n",
    "#   seg.setMaxIterations (100);\n",
    "#   seg.setDistanceThreshold (0.02);\n",
    "seg = cloud.make_segmenter()\n",
    "seg.set_optimize_coefficients (True)\n",
    "seg.set_model_type (pcl.SACMODEL_PLANE)\n",
    "seg.set_method_type (pcl.SAC_RANSAC)\n",
    "seg.set_MaxIterations (100)\n",
    "seg.set_distance_threshold (0.02)\n",
    "\n",
    "#   int i=0, nr_points = (int) cloud_filtered->points.size ();\n",
    "#   while (cloud_filtered->points.size () > 0.3 * nr_points)\n",
    "#   {\n",
    "#     // Segment the largest planar component from the remaining cloud\n",
    "#     seg.setInputCloud (cloud_filtered);\n",
    "#     seg.segment (*inliers, *coefficients);\n",
    "#     if (inliers->indices.size () == 0)\n",
    "#     {\n",
    "#       std::cout << \"Could not estimate a planar model for the given dataset.\" << std::endl;\n",
    "#       break;\n",
    "#     }\n",
    "#     // Extract the planar inliers from the input cloud\n",
    "#     pcl::ExtractIndices<pcl::PointXYZ> extract;\n",
    "#     extract.setInputCloud (cloud_filtered);\n",
    "#     extract.setIndices (inliers);\n",
    "#     extract.setNegative (false);\n",
    "# \n",
    "#     // Get the points associated with the planar surface\n",
    "#     extract.filter (*cloud_plane);\n",
    "#     std::cout << \"PointCloud representing the planar component: \" << cloud_plane->points.size () << \" data points.\" << std::endl;\n",
    "# \n",
    "#     // Remove the planar inliers, extract the rest\n",
    "#     extract.setNegative (true);\n",
    "#     extract.filter (*cloud_f);\n",
    "#     *cloud_filtered = *cloud_f;\n",
    "#   }\n",
    "\n",
    "i = 0\n",
    "nr_points = cloud_filtered.size\n",
    "# while nr_points > 0.3 * nr_points:\n",
    "#     # Segment the largest planar component from the remaining cloud\n",
    "#     [inliers, coefficients] = seg.segment()\n",
    "#     # extract = cloud_filtered.extract()\n",
    "#     # extract = pcl.PointIndices()\n",
    "#     cloud_filtered.extract(extract)\n",
    "#     extract.set_Indices (inliers)\n",
    "#     extract.set_Negative (false)\n",
    "#     cloud_plane = extract.filter ()\n",
    "#     \n",
    "#     extract.set_Negative (True)\n",
    "#     cloud_f = extract.filter ()\n",
    "#     cloud_filtered = cloud_f\n",
    "\n",
    "\n",
    "# Creating the KdTree object for the search method of the extraction\n",
    "# pcl::search::KdTree<pcl::PointXYZ>::Ptr tree (new pcl::search::KdTree<pcl::PointXYZ>);\n",
    "# tree->setInputCloud (cloud_filtered);\n",
    "tree = cloud_filtered.make_kdtree()\n",
    "# tree = cloud_filtered.make_kdtree_flann()\n",
    "\n",
    "\n",
    "# std::vector<pcl::PointIndices> cluster_indices;\n",
    "# pcl::EuclideanClusterExtraction<pcl::PointXYZ> ec;\n",
    "# ec.setClusterTolerance (0.02); // 2cm\n",
    "# ec.setMinClusterSize (100);\n",
    "# ec.setMaxClusterSize (25000);\n",
    "# ec.setSearchMethod (tree);\n",
    "# ec.setInputCloud (cloud_filtered);\n",
    "# ec.extract (cluster_indices);\n",
    "ec = cloud_filtered.make_EuclideanClusterExtraction()\n",
    "ec.set_ClusterTolerance (0.02)\n",
    "ec.set_MinClusterSize (100)\n",
    "ec.set_MaxClusterSize (25000)\n",
    "ec.set_SearchMethod (tree)\n",
    "cluster_indices = ec.Extract()\n",
    "\n",
    "print('cluster_indices : ' + str(cluster_indices.count) + \" count.\")\n",
    "# print('cluster_indices : ' + str(cluster_indices.indices.max_size) + \" count.\")\n",
    "\n",
    "#   int j = 0;\n",
    "#   for (std::vector<pcl::PointIndices>::const_iterator it = cluster_indices.begin (); it != cluster_indices.end (); ++it)\n",
    "#   {\n",
    "#     pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_cluster (new pcl::PointCloud<pcl::PointXYZ>);\n",
    "#     for (std::vector<int>::const_iterator pit = it->indices.begin (); pit != it->indices.end (); ++pit)\n",
    "#       cloud_cluster->points.push_back (cloud_filtered->points[*pit]); //*\n",
    "#     cloud_cluster->width = cloud_cluster->points.size ();\n",
    "#     cloud_cluster->height = 1;\n",
    "#     cloud_cluster->is_dense = true;\n",
    "# \n",
    "#     std::cout << \"PointCloud representing the Cluster: \" << cloud_cluster->points.size () << \" data points.\" << std::endl;\n",
    "#     std::stringstream ss;\n",
    "#     ss << \"cloud_cluster_\" << j << \".pcd\";\n",
    "#     writer.write<pcl::PointXYZ> (ss.str (), *cloud_cluster, false); //*\n",
    "#     j++;\n",
    "#   }\n",
    "# \n",
    "\n",
    "cloud_cluster = pcl.PointCloud()\n",
    "obj_mean = np.empty([len(cluster_indices),2],dtype = float)\n",
    "\n",
    "for j, indices in enumerate(cluster_indices):\n",
    "    # cloudsize = indices\n",
    "    print('indices = ' + str(len(indices)))\n",
    "    # cloudsize = len(indices)\n",
    "    points = np.zeros((len(indices), 3), dtype=np.float32)\n",
    "    # points = np.zeros((cloudsize, 3), dtype=np.float32)\n",
    "    \n",
    "    # for indice in range(len(indices)):\n",
    "    for i, indice in enumerate(indices):\n",
    "        # print('dataNum = ' + str(i) + ', data point[x y z]: ' + str(cloud_filtered[indice][0]) + ' ' + str(cloud_filtered[indice][1]) + ' ' + str(cloud_filtered[indice][2]))\n",
    "        # print('PointCloud representing the Cluster: ' + str(cloud_cluster.size) + \" data points.\")\n",
    "        points[i][0] = cloud_filtered[indice][0]\n",
    "        points[i][1] = cloud_filtered[indice][1]\n",
    "        points[i][2] = cloud_filtered[indice][2]\n",
    "    \n",
    "    x_mean = (points[:,0].max()+points[:,0].min())/2\n",
    "    y_mean = (points[:,1].max()+points[:,1].min())/2\n",
    "    dot_mean = np.hstack((x_mean,y_mean))\n",
    "    obj_mean[j,:] = dot_mean\n",
    "    \n",
    "#     cloud_cluster.from_array(points)\n",
    "#     ss = \"cloud_cluster_\" + str(j) + \".pcd\";\n",
    "#     pcl.save(cloud_cluster, ss)\n",
    "#     ss_matlab = \"cloud_cluster_\" + str(j) + \".mat\";\n",
    "#     scio.savemat(ss_matlab, {'A':cloud_cluster})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot prediction by obj_mean\n",
    "type(obj_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
